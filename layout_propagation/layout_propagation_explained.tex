% !TeX program = xelatex
% -*- coding: utf-8 -*-
\documentclass[11pt]{ctexart}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{amsmath,amssymb,mathtools}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, urlcolor=blue}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{algorithm}
\usepackage{algpseudocode}
\setlist{nosep}
\emergencystretch=2em

% 代码样式设置
\lstset{
  language=Python,
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue},
  commentstyle=\color{green!60!black},
  stringstyle=\color{red!60!black},
  numbers=left,
  numberstyle=\tiny\color{gray},
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{gray!10},
  frame=single,
  rulecolor=\color{gray!30},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4,
  showstringspaces=false
}

\title{神经网络加速器中的数据布局变换：\\原理、实现与优化}
\author{nn\_dataflow 项目文档}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
数据布局（Data Layout）是深度学习加速器设计中的关键问题。本文系统性地阐述了数据布局的基本概念、布局变换的实现机制以及优化策略。重点讨论了以下核心问题：（1）布局变换应作用于权重还是激活值；（2）布局变换应与哪个算子融合实现；（3）变换应在读取阶段还是写入阶段完成；（4）实现布局变换的硬件单元设计。本文结合具体代码实现，详细分析了各种设计权衡，为神经网络加速器的设计提供参考。
\end{abstract}

\tableofcontents
\newpage

%======================================================================
\section{什么是数据布局}
%======================================================================

\textbf{数据布局（Data Layout）}的本质是一个映射：

\begin{center}
\fbox{\parbox{0.85\textwidth}{\centering
\textbf{逻辑索引 $(n, c, h, w)$ $\longrightarrow$ 物理地址 addr}
}}
\end{center}

给定一个多维张量的逻辑坐标，布局决定了它在内存中的实际存储位置。

%======================================================================
\section{为什么需要布局}
%======================================================================

\subsection{问题：多维数据 vs 一维内存}

张量是多维的，例如一个特征图有 4 个维度：
\begin{itemize}
  \item $N$ — 批次（batch）
  \item $C$ — 通道（channel）
  \item $H$ — 高度（height）
  \item $W$ — 宽度（width）
\end{itemize}

但物理内存是一维的线性地址空间。布局定义了如何把多维索引"展平"到一维地址。

\subsection{不同的展平方式}

同一个张量，不同的布局会产生完全不同的内存排列：

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{布局} & \textbf{地址计算} & \textbf{特点} \\
\midrule
NCHW & $n \cdot CHW + c \cdot HW + h \cdot W + w$ & 通道优先（PyTorch 默认） \\
NHWC & $n \cdot HWC + h \cdot WC + w \cdot C + c$ & 空间优先（TensorFlow 默认） \\
\bottomrule
\end{tabular}
\end{center}

%======================================================================
\section{布局的形式化定义}
%======================================================================

\subsection{基本形式}

设张量的形状为 $(D_0, D_1, \ldots, D_{k-1})$，布局可以表示为一个排列 $\pi$ 和对应的步长（stride）向量 $\mathbf{s}$：

\begin{equation}
  \text{addr}(i_0, i_1, \ldots, i_{k-1}) = \text{base} + \sum_{j=0}^{k-1} i_j \cdot s_j
\end{equation}

其中 $s_j$ 是第 $j$ 维的步长，决定了该维索引增加 1 时地址的增量。

\subsection{步长的含义}

以 NCHW 布局为例，形状为 $(N, C, H, W)$ 的张量：
\begin{align}
  s_W &= 1 & \text{（W 维连续）} \\
  s_H &= W & \text{（H 维跨 W 个元素）} \\
  s_C &= H \times W & \text{（C 维跨一个空间平面）} \\
  s_N &= C \times H \times W & \text{（N 维跨一个完整样本）}
\end{align}

\subsection{紧凑布局 vs 非紧凑布局}

\paragraph{紧凑布局} 步长严格按维度大小递推，没有空隙：
\[
  s_{\pi(j)} = \prod_{i<j} D_{\pi(i)}
\]

\paragraph{非紧凑布局} 步长可以任意指定，可能存在：
\begin{itemize}
  \item \textbf{Padding}：步长大于所需，元素之间有空隙
  \item \textbf{子视图}：从更大张量中切出的子区域
  \item \textbf{广播}：某维步长为 0，表示该维重复使用同一数据
\end{itemize}

%======================================================================
\section{常见布局类型}
%======================================================================

\subsection{连续布局}

最简单的布局，维度按固定顺序排列：

\begin{itemize}
  \item \textbf{NCHW}：先遍历 W，再 H，再 C，最后 N
  \item \textbf{NHWC}：先遍历 C，再 W，再 H，最后 N
  \item \textbf{CHWN}：先遍历 N，再 W，再 H，最后 C
\end{itemize}

\subsection{分块布局（Tiled Layout）}

将张量按固定大小分块，块内和块间可以有不同的排列顺序。

例如 NCHW 按 $8 \times 8$ 分块：
\begin{verbatim}
for n in range(N):
    for c in range(C):
        for h_tile in range(H // 8):
            for w_tile in range(W // 8):
                for h_in_tile in range(8):      # 块内
                    for w_in_tile in range(8):  # 块内
                        addr = ...
\end{verbatim}

分块布局对硬件友好，因为：
\begin{itemize}
  \item 块大小可以匹配缓存行或 SRAM 大小
  \item 块内访问连续，提高局部性
\end{itemize}

\subsection{交错布局（Interleaved Layout）}

将某个维度的元素交错存放，常用于向量化访问。

例如通道交错（channel interleaving）：每 $k$ 个通道的同一空间位置连续存放。

%======================================================================
\section{布局对性能的影响}
%======================================================================

\subsection{访存局部性}

不同的布局决定了访问模式的局部性：

\begin{itemize}
  \item \textbf{卷积}：NCHW 布局下，空间维度连续，利于滑动窗口访问
  \item \textbf{通道拼接}：NHWC 布局下，通道连续，拼接操作更高效
  \item \textbf{批处理}：如果 N 在最内层，同一位置的不同样本连续
\end{itemize}

\subsection{硬件适配}

不同硬件偏好不同布局：

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{硬件} & \textbf{偏好布局} \\
\midrule
NVIDIA GPU (cuDNN) & NCHW 或 NHWC（取决于算法） \\
Intel CPU (MKL-DNN) & 分块布局（如 nChw16c） \\
TPU & NHWC \\
自定义加速器 & 取决于数据通路设计 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{布局转换的代价}

当上下游算子需要不同布局时，需要进行\textbf{布局转换}（layout transform）：

\begin{itemize}
  \item 本质是一次内存重排（memory transpose）
  \item 代价 = 读取全部数据 + 写入全部数据
  \item 应尽量避免，或与其他操作融合
\end{itemize}

%======================================================================
\section{布局传播}
%======================================================================

\subsection{定义}

\textbf{布局传播}是指：在神经网络的计算图中，根据算子语义和上游布局，推导下游数据的布局。

\subsection{传播规则}

\paragraph{恒等传播} 逐元素算子（ReLU、Add）保持输入布局不变。

\paragraph{转置传播} Transpose/Permute 改变维度顺序，相应调整步长。

\paragraph{卷积传播} 输入输出通常保持相同的空间布局，但通道维度可能变化。

\paragraph{重塑传播} Reshape 可能需要转换为连续布局才能正确重塑。

\subsection{传播的作用}

\begin{enumerate}
  \item 确定每个中间张量的内存布局
  \item 识别需要布局转换的位置
  \item 为代价模型提供访存模式信息
\end{enumerate}

%======================================================================
\section{工程实现}
%======================================================================

\subsection{布局的表示}

常见的表示方式：

\begin{verbatim}
# 方式1：步长表示
layout = {
    'shape': (N, C, H, W),
    'strides': (C*H*W, H*W, W, 1)  # NCHW
}

# 方式2：维度顺序表示
layout = 'NCHW'  # 或 'NHWC'

# 方式3：分块表示
layout = {
    'outer': 'NCHW',
    'tile_size': (1, 8, 8, 8),
    'inner': 'CHWN'
}
\end{verbatim}

\subsection{地址计算}

给定布局和索引，计算地址：

\begin{verbatim}
def compute_addr(index, strides, base=0):
    addr = base
    for i, s in zip(index, strides):
        addr += i * s
    return addr
\end{verbatim}

%======================================================================
\section{Data Layout 的底层实现}
%======================================================================

本节解释深度学习框架（如 PyTorch、NumPy）如何在底层实现 Data Layout。

\subsection{张量的核心数据结构}

一个张量在内存中由两部分组成：

\begin{enumerate}
  \item \textbf{数据存储（Storage）}：一块连续的原始内存
  \item \textbf{元数据（Metadata）}：描述如何解释这块内存
\end{enumerate}

\begin{verbatim}
class Tensor:
    storage: ptr         # 指向原始数据的指针
    shape: tuple         # 形状，如 (2, 3, 4)
    strides: tuple       # 步长，如 (12, 4, 1)
    offset: int          # 起始偏移（默认为 0）
    dtype: DataType      # 数据类型，如 float32
\end{verbatim}

\paragraph{关键点}：\textbf{多个张量可以共享同一块 storage}，只是用不同的元数据来"解释"它。

\subsection{步长如何实现布局}

步长（strides）是实现布局的核心机制：

\begin{verbatim}
# PyTorch 示例
import torch

x = torch.randn(2, 3, 4)
print(x.shape)    # torch.Size([2, 3, 4])
print(x.stride()) # (12, 4, 1)  -- 紧凑 C 顺序

# 地址计算：x[i,j,k] 的地址 = base + i*12 + j*4 + k*1
\end{verbatim}

\subsubsection{不同布局对应不同步长}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{布局} & \textbf{shape} & \textbf{strides} \\
\midrule
NCHW（PyTorch 默认） & (N, C, H, W) & (C*H*W, H*W, W, 1) \\
NHWC（TensorFlow 默认） & (N, H, W, C) & (H*W*C, W*C, C, 1) \\
Fortran 顺序 & (M, N) & (1, M) \\
\bottomrule
\end{tabular}
\end{center}

\subsection{零拷贝操作的实现}

许多操作不需要移动数据，只需要修改元数据：

\subsubsection{Transpose（转置）}

\begin{verbatim}
x = torch.randn(2, 3, 4)
print(x.stride())           # (12, 4, 1)

y = x.transpose(1, 2)       # 交换维度 1 和 2
print(y.shape)              # torch.Size([2, 4, 3])
print(y.stride())           # (12, 1, 4)  -- 步长交换！

# x 和 y 共享同一块内存，只是步长不同
print(x.data_ptr() == y.data_ptr())  # True
\end{verbatim}

\subsubsection{Slice（切片）}

\begin{verbatim}
x = torch.randn(10, 20)
print(x.stride())           # (20, 1)

y = x[2:8, 5:15]            # 切出子区域
print(y.shape)              # torch.Size([6, 10])
print(y.stride())           # (20, 1)  -- 步长不变
print(y.storage_offset())   # 45 = 2*20 + 5

# y 是 x 的视图，指向同一块 storage，但偏移不同
\end{verbatim}

\subsubsection{Reshape（重塑）}

\begin{verbatim}
x = torch.randn(2, 3, 4)
print(x.stride())           # (12, 4, 1)

y = x.reshape(6, 4)         # 如果连续，只改元数据
print(y.stride())           # (4, 1)

# 如果不连续，reshape 会先拷贝数据
x_t = x.transpose(1, 2)     # 非连续
print(x_t.is_contiguous())  # False
y_t = x_t.reshape(6, 4)     # 这会触发拷贝！
\end{verbatim}

\subsection{连续性检查}

\textbf{连续（contiguous）}意味着步长严格递减且相邻元素在内存中相邻：

\begin{verbatim}
def is_contiguous(shape, strides):
    """检查是否为 C 顺序连续"""
    expected_stride = 1
    for dim, stride in reversed(list(zip(shape, strides))):
        if stride != expected_stride:
            return False
        expected_stride *= dim
    return True
\end{verbatim}

许多算子（如 GEMM）要求输入连续，非连续张量需要先调用 \texttt{.contiguous()} 复制为连续布局。

\subsection{完整的地址计算流程}

\begin{verbatim}
def tensor_element_address(tensor, *indices):
    """
    计算 tensor[i0, i1, ..., ik] 的内存地址
    """
    # 1. 检查索引有效性
    for idx, (i, dim) in enumerate(zip(indices, tensor.shape)):
        assert 0 <= i < dim, f"Index {idx} out of bounds"
    
    # 2. 计算相对偏移
    offset = tensor.storage_offset
    for i, stride in zip(indices, tensor.strides):
        offset += i * stride
    
    # 3. 计算绝对地址
    element_size = sizeof(tensor.dtype)  # 如 float32 = 4 bytes
    byte_address = tensor.storage.data_ptr + offset * element_size
    
    return byte_address
\end{verbatim}

\subsection{广播的实现：零步长}

广播（broadcast）通过将某维度的步长设为 0 来实现：

\begin{verbatim}
# 原始向量 (3,)
a = torch.tensor([1, 2, 3])
print(a.stride())           # (1,)

# 扩展为 (4, 3)，但不复制数据
b = a.expand(4, 3)
print(b.shape)              # torch.Size([4, 3])
print(b.stride())           # (0, 1)  -- 第一维步长为 0！

# b[0,:], b[1,:], b[2,:], b[3,:] 都指向同一行
\end{verbatim}

步长为 0 意味着该维度的索引变化不影响地址，实现了"虚拟复制"。

\subsection{实现总结}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{操作} & \textbf{实现方式} & \textbf{是否拷贝} \\
\midrule
创建张量 & 分配 storage + 设置 strides & 是（初始分配） \\
Transpose & 交换 strides 和 shape & 否 \\
Slice & 调整 offset + shape & 否 \\
Reshape（连续时） & 重算 strides & 否 \\
Reshape（非连续时） & 先拷贝再重算 & 是 \\
Expand/Broadcast & 插入步长为 0 的维度 & 否 \\
Contiguous & 复制到新 storage & 是 \\
\bottomrule
\end{tabular}
\end{center}

%======================================================================
\section{布局变换融合}
%======================================================================

当计算图中存在多个连续的布局变换时，可以将它们\textbf{融合}为一个变换，减少内存访问。

\subsection{变换的本质：索引映射}

每个布局变换本质上是一个索引映射函数：
\[
  T: \text{index}_{\text{old}} \longrightarrow \text{index}_{\text{new}}
\]

完整的数据搬运涉及两步：
\begin{align}
  \text{addr}_{\text{src}} &= \text{layout}_{\text{src}}(\text{index}) \\
  \text{addr}_{\text{dst}} &= \text{layout}_{\text{dst}}(T(\text{index}))
\end{align}

\subsection{多次变换 = 映射的复合}

假设有两个连续变换 $T_1$ 和 $T_2$：

\paragraph{不融合}（3 次内存访问）：
\begin{verbatim}
原数据 --读取--> 中间结果1 --写入-->
中间结果1 --读取--> 中间结果2 --写入-->
\end{verbatim}

\paragraph{融合}（1 次内存访问）：
\[
  \text{addr}_{\text{dst}} = \text{layout}_{\text{dst}}(T_2(T_1(\text{index}))) 
                           = \text{layout}_{\text{dst}}((T_2 \circ T_1)(\text{index}))
\]

\subsection{例子：两次 Transpose 的融合}

考虑 NCHW $\to$ NHWC $\to$ NCHW：

\begin{center}
\begin{tabular}{ll}
\toprule
\textbf{变换} & \textbf{映射} \\
\midrule
$T_1$ & $(n,c,h,w) \to (n,h,w,c)$ \\
$T_2$ & $(n,h,w,c) \to (n,c,h,w)$ \\
$T_2 \circ T_1$ & $(n,c,h,w) \to (n,c,h,w)$ = 恒等映射 \\
\bottomrule
\end{tabular}
\end{center}

融合结果：两次转置抵消，\textbf{不需要任何数据搬运}。

\subsection{例子：Reshape + Transpose 融合}

原始张量 $(1, 64, 56, 56)$ NCHW，目标布局 $(1, 3136, 64)$：

\paragraph{不融合}：
\begin{enumerate}
  \item Reshape: $(1, 64, 56, 56) \to (1, 64, 3136)$，写入临时缓冲
  \item Transpose: $(1, 64, 3136) \to (1, 3136, 64)$，写入最终结果
\end{enumerate}

\paragraph{融合}：直接计算复合地址映射
\begin{verbatim}
def fused_transform(n, c, h, w):
    src_addr = n*64*56*56 + c*56*56 + h*56 + w   # NCHW
    dst_addr = n*3136*64 + (h*56+w)*64 + c        # (1,3136,64)
    return src_addr, dst_addr
\end{verbatim}

一次读取源地址，一次写入目标地址，省掉中间缓冲。

\subsection{融合的条件}

\begin{enumerate}
  \item \textbf{代数可消}：$T_2 \circ T_1 = I$（恒等映射）
  \item \textbf{代数可简化}：复合映射比分开执行更简单
  \item \textbf{硬件支持}：地址生成器能实现复合映射（如支持任意步长）
\end{enumerate}

\subsection{工程实现}

融合后的变换在 DMA 或地址生成器中实现：

\begin{verbatim}
# 不融合：两次 memcpy
tmp = transpose(src, perm1)
dst = transpose(tmp, perm2)

# 融合：一次 memcpy，复合地址计算
for idx in all_indices:
    src_addr = compute_src_addr(idx)
    dst_addr = compute_fused_dst_addr(idx)  # T2(T1(idx))
    dst[dst_addr] = src[src_addr]
\end{verbatim}

\subsection{融合的收益}

\begin{center}
\begin{tabular}{lll}
\toprule
 & \textbf{不融合} & \textbf{融合} \\
\midrule
内存访问 & 多次读写 & 一次读写 \\
中间缓冲 & 需要 & 不需要 \\
地址计算 & 简单 & 复杂但一次完成 \\
\bottomrule
\end{tabular}
\end{center}

%======================================================================
\section{布局变换算子的分类}
%======================================================================

并非所有"布局变换"都是纯粹的索引重映射。根据映射的数学性质，可以将其分为三类。

\subsection{纯索引重映射（Bijective）}

这类变换是\textbf{双射}：输入和输出元素一一对应，数据总量不变。

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{算子} & \textbf{映射} & \textbf{特点} \\
\midrule
Transpose & $(n,c,h,w) \to (n,h,w,c)$ & 维度置换 \\
Reshape & $(n,c,h,w) \to (n, c \cdot h \cdot w)$ & 维度合并/拆分 \\
Permute & 任意维度重排 & Transpose 的一般化 \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{核心性质}：
\begin{itemize}
  \item 完全可逆
  \item 可以实现为"零拷贝"（只改变步长/元数据）
  \item 多个变换可融合为复合映射
\end{itemize}

\subsection{数据重组（Non-bijective，数据增加）}

这类变换会\textbf{复制数据}，输出元素多于输入元素。

\subsubsection{im2col：典型的数据膨胀算子}

im2col 将卷积运算转换为矩阵乘法：
\[
  \text{im2col}: \mathbb{R}^{N \times C \times H \times W} \to \mathbb{R}^{(N \cdot H_{out} \cdot W_{out}) \times (C \cdot K_h \cdot K_w)}
\]

\paragraph{为什么数据量增加}：卷积滑窗有重叠，同一输入元素被复制多次。

\begin{verbatim}
输入 3×3，卷积核 2×2，stride=1:

  [a b c]      im2col 矩阵（每行是一个展开的 patch）:
  [d e f]  →   [a b d e]   ← 位置(0,0)
  [g h i]      [b c e f]   ← 位置(0,1)，b和e被复制
               [d e g h]   ← 位置(1,0)
               [e f h i]   ← 位置(1,1)

输入 9 个元素 → 输出 16 个元素，元素 e 出现了 4 次
\end{verbatim}

\paragraph{数学表示}：im2col 是一个 \textbf{gather 操作}：
\[
  M[i, j] = X[\text{gather\_index}(i, j)]
\]
其中 gather\_index 不是单射——多个 $(i,j)$ 可以指向同一个输入位置。

\paragraph{其他类似算子}：
\begin{itemize}
  \item \texttt{unfold} — im2col 的 PyTorch 版本
  \item \texttt{repeat} / \texttt{tile} — 显式复制
  \item \texttt{broadcast} — 隐式复制（不物化）
\end{itemize}

\subsubsection{显式 vs 隐式 im2col}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{方式} & \textbf{内存开销} & \textbf{实现} \\
\midrule
显式 im2col & 高（真正复制数据） & \texttt{torch.nn.functional.unfold} \\
隐式 im2col & 零（不物化） & cuDNN implicit GEMM \\
\bottomrule
\end{tabular}
\end{center}

隐式 im2col 的思路：不创建中间矩阵，而是在 GEMM 内部动态计算源地址。

\begin{verbatim}
# 隐式 im2col：融合 gather 到计算中
for out_row, out_col in output_positions:
    for k in reduction_dim:
        # 根据 (out_row, out_col, k) 计算输入地址
        in_addr = compute_input_addr(out_row, out_col, k)
        result[out_row, out_col] += input[in_addr] * weight[k, out_col]
\end{verbatim}

\subsection{数据选择（数据减少）}

这类变换选取部分数据，输出元素少于输入元素。

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{算子} & \textbf{操作} & \textbf{特点} \\
\midrule
Slice & 连续子区域 & 可通过调整 base + shape 实现 \\
Gather / Index\_select & 任意位置 & 需要索引数组 \\
Squeeze & 删除大小为1的维度 & 零拷贝 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{分类总结}

\begin{center}
\begin{tabular}{llll}
\toprule
\textbf{类别} & \textbf{映射性质} & \textbf{数据量} & \textbf{可融合性} \\
\midrule
纯索引重映射 & 双射 & 不变 & 可融合为复合映射 \\
数据重组 & 非单射（多对一的逆） & 增加 & 需决定是否物化 \\
数据选择 & 非满射 & 减少 & 可部分融合 \\
\bottomrule
\end{tabular}
\end{center}

\paragraph{硬件映射启示}：
\begin{itemize}
  \item 纯索引重映射：可完全通过地址生成器实现，零额外内存
  \item 数据重组（如 im2col）：需权衡"显式物化"（内存换规整计算）vs "隐式计算"（省内存但访问复杂）
  \item 数据选择：通常可通过调整地址范围实现
\end{itemize}

%======================================================================
\section{Layout Transformation 的对象：权重 vs 激活值}
%======================================================================

布局变换可以应用于神经网络中的两类数据：\textbf{权重（Weight）}和\textbf{激活值（Activation）}。两者在变换时机、代价和优化策略上有本质区别。

\subsection{权重的布局变换}

\subsubsection{特点分析}

权重数据具有以下特性：
\begin{itemize}
  \item \textbf{静态性}：推理阶段权重固定不变
  \item \textbf{可预处理}：可在编译期/部署前完成布局变换
  \item \textbf{一次变换}：只需变换一次，可被所有输入复用
  \item \textbf{存储于外部内存}：通常存储在 DRAM/Flash 中
\end{itemize}

\subsubsection{优化策略}

由于权重的静态特性，最佳策略是\textbf{离线预处理}：

\begin{lstlisting}[caption={权重布局预处理示例}]
class WeightLayoutOptimizer:
    """
    权重布局优化器
    
    在模型部署前，将权重转换为硬件最优布局
    """
    
    @staticmethod
    def preprocess_weight(weight, target_layout):
        """
        离线预处理权重布局
        
        Args:
            weight: 原始权重 (OIHW format)
            target_layout: 目标布局，如 (0, 2, 3, 1) for OHWI
            
        Returns:
            变换后的权重，直接以目标布局存储
        """
        # 计算目标布局的步长
        shape = weight.shape
        target_strides = compute_permuted_strides(shape, target_layout)
        
        # 创建新的存储并按目标布局写入
        new_weight = allocate_storage(shape, target_strides)
        
        # 一次性完成变换（离线执行，不影响推理延迟）
        for idx in iterate_all_indices(shape):
            src_addr = compute_addr(idx, weight.strides)
            dst_addr = compute_addr(idx, target_strides)
            new_weight[dst_addr] = weight[src_addr]
        
        return new_weight
\end{lstlisting}

\subsubsection{代价分析}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{阶段} & \textbf{代价} & \textbf{影响} \\
\midrule
离线预处理 & $O(|W|)$ 内存访问 & 不影响推理延迟 \\
模型部署 & 存储空间增加（如果保留原始权重） & 可接受 \\
推理时 & 零额外开销 & 最优 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{激活值的布局变换}

\subsubsection{特点分析}

激活值数据具有以下特性：
\begin{itemize}
  \item \textbf{动态性}：每次推理都会产生新的激活值
  \item \textbf{无法预处理}：必须在运行时完成变换
  \item \textbf{数据量大}：通常比权重大（尤其是大 batch 时）
  \item \textbf{生命周期短}：中间激活值可以及时释放
\end{itemize}

\subsubsection{挑战}

激活值的布局变换是推理延迟的关键因素：

\begin{lstlisting}[caption={激活值布局变换的代价模型}]
class ActivationLayoutCost:
    """
    激活值布局变换的代价模型
    """
    
    @staticmethod
    def estimate_transform_cost(shape, src_layout, dst_layout, 
                                 mem_config):
        """
        估算激活值布局变换的代价
        
        Args:
            shape: 激活值形状 (N, C, H, W)
            src_layout: 源布局
            dst_layout: 目标布局
            mem_config: 内存配置
            
        Returns:
            cycles: 执行周期数
            energy: 能耗 (pJ)
        """
        data_size = prod(shape) * 4  # float32
        
        if src_layout == dst_layout:
            return 0, 0  # 无需变换
        
        # 单独的 layout transform 算子 (DRAM -> DRAM)
        # 需要读取全部数据 + 写入全部数据
        read_cycles = data_size / mem_config.dram_bandwidth
        write_cycles = data_size / mem_config.dram_bandwidth
        total_cycles = read_cycles + write_cycles + 2 * mem_config.dram_latency
        
        energy = 2 * data_size * mem_config.dram_energy_per_byte
        
        return total_cycles, energy
\end{lstlisting}

\subsection{权重 vs 激活值：决策总结}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{特性} & \textbf{权重} & \textbf{激活值} \\
\midrule
变换时机 & 离线预处理 & 运行时 \\
代价分摊 & 一次变换，多次推理复用 & 每次推理都需要 \\
优化策略 & 编译期确定最优布局 & 融合到算子/内存拷贝 \\
存储位置 & DRAM/Flash（持久存储） & SRAM/DRAM（临时） \\
\bottomrule
\end{tabular}
\end{center}

\textbf{核心原则}：
\begin{itemize}
  \item 权重布局变换应在\textbf{离线阶段}完成，零运行时开销
  \item 激活值布局变换应\textbf{融合到其他操作}中，避免单独的变换算子
\end{itemize}

%======================================================================
\section{Layout Transformation 与算子融合}
%======================================================================

当激活值需要布局变换时，关键问题是：\textbf{变换应该与哪个算子融合}？

\subsection{融合位置的选择}

考虑以下计算图：
\[
  \text{Conv}_1 \xrightarrow{\text{NCHW}} \text{ReLU} \xrightarrow{\text{NCHW}} \text{?变换?} \xrightarrow{\text{NHWC}} \text{Conv}_2
\]

有三种可能的融合策略：

\subsubsection{策略 A：与 Producer（生产者）融合}

变换融合到上游算子（如 $\text{Conv}_1$ 或 $\text{ReLU}$）的输出阶段：

\begin{lstlisting}[caption={Producer 融合策略}]
class ProducerFusedTransform:
    """
    将 Layout Transform 融合到 Producer 的写入阶段
    
    Producer 计算完成后，按照 Consumer 期望的 layout 生成写地址
    """
    
    @staticmethod
    def create_write_address_generator(shape, producer_compute_order,
                                        target_layout, base_addr=0):
        """
        创建融合 layout 变换的写入地址生成器
        
        Producer 在写回结果时，直接按 target_layout 写入，
        避免后续的显式 layout transform
        """
        # 计算目标 layout 的步长
        target_strides = compute_strides(shape, target_layout)
        
        return AddressPattern(
            base_addr=base_addr,
            shape=shape,
            strides=target_strides,  # 按目标布局的步长写入
            loop_order=producer_compute_order
        )
\end{lstlisting}

\textbf{适用场景}：
\begin{itemize}
  \item Producer 的输出被多个 Consumer 使用，且它们期望相同布局
  \item Producer 的计算循环顺序与目标布局兼容
\end{itemize}

\subsubsection{策略 B：与 Consumer（消费者）融合}

变换融合到下游算子（如 $\text{Conv}_2$）的输入读取阶段：

\begin{lstlisting}[caption={Consumer 融合策略}]
class ConsumerFusedTransform:
    """
    将 Layout Transform 融合到 Consumer 的读取阶段
    
    Consumer 按照上游实际存储的 layout 生成读地址
    """
    
    @staticmethod
    def create_read_address_generator(shape, source_layout,
                                       consumer_compute_order, base_addr=0):
        """
        创建融合 layout 变换的读取地址生成器
        
        Consumer 读取时，按 source_layout 计算读地址，
        数据在读取过程中被重新排列到计算单元期望的顺序
        """
        # 计算源 layout 的步长
        source_strides = compute_strides(shape, source_layout)
        
        return AddressPattern(
            base_addr=base_addr,
            shape=shape,
            strides=source_strides,  # 按源布局的步长读取
            loop_order=consumer_compute_order
        )
\end{lstlisting}

\textbf{适用场景}：
\begin{itemize}
  \item 上游数据有多种可能的布局（如来自不同分支）
  \item Consumer 对读取顺序有灵活性
\end{itemize}

\subsubsection{策略 C：与 Memory Copy 融合}

变换融合到内存层次之间的数据搬移（如 DRAM $\to$ SRAM）：

\begin{lstlisting}[caption={Memory Copy 融合策略}]
class MemoryCopyFusedTransform:
    """
    将 Layout Transform 融合到 Memory Copy 过程
    
    在 DRAM -> SRAM 的必需搬移中完成布局变换
    """
    
    @staticmethod
    def create_fused_copy_generator(shape, source_layout, target_layout):
        """
        创建融合 layout 变换的 memory copy 地址生成器对
        """
        source_strides = compute_strides(shape, source_layout)
        target_strides = compute_strides(shape, target_layout)
        
        # 确定最优遍历顺序（优先让读取连续）
        read_order = optimal_traverse_order(source_strides)
        
        read_pattern = AddressPattern(
            shape=shape,
            strides=source_strides,
            loop_order=read_order
        )
        
        write_pattern = AddressPattern(
            shape=shape,
            strides=target_strides,
            loop_order=read_order  # 使用相同遍历顺序
        )
        
        return read_pattern, write_pattern
\end{lstlisting}

\textbf{适用场景}：
\begin{itemize}
  \item 数据需要从 DRAM 预取到 SRAM
  \item 变换可以隐藏在必需的数据搬移延迟中
\end{itemize}

\subsection{融合策略的代价比较}

\begin{center}
\begin{tabular}{llll}
\toprule
\textbf{策略} & \textbf{额外 DRAM 访问} & \textbf{硬件要求} & \textbf{灵活性} \\
\midrule
单独 Transform 算子 & 2× (读+写) & 简单 & 差 \\
Producer 融合 & 0× & 灵活地址生成 & 中 \\
Consumer 融合 & 0× & 灵活地址生成 & 高 \\
Memory Copy 融合 & 0× & DMA 支持 & 高 \\
\bottomrule
\end{tabular}
\end{center}

\subsection{代码实现：算子间 Layout 协商}

\begin{lstlisting}[caption={Layout 协商器实现}]
class OperatorLayoutNegotiator:
    """
    算子间 Layout 协商器
    
    在相邻算子之间协商 layout，决定最优的变换策略
    """
    
    def negotiate(self, producer, consumer, tensor_name):
        """
        协商两个算子之间的 layout 处理方式
        """
        producer_layout = producer.output_layouts[tensor_name]
        consumer_layout = consumer.input_layouts[tensor_name]
        shape = producer.output_shapes[tensor_name]
        
        if producer_layout == consumer_layout:
            return {"transform_needed": False, "strategy": "DIRECT"}
        
        # 比较不同策略的代价
        strategies = []
        
        # 策略 1: Producer 写入时变换
        cost_1 = self.estimate_producer_transform_cost(
            shape, producer, consumer_layout)
        strategies.append(("PRODUCER_WRITE_TRANSFORM", cost_1))
        
        # 策略 2: Consumer 读取时变换
        cost_2 = self.estimate_consumer_transform_cost(
            shape, producer_layout, consumer)
        strategies.append(("CONSUMER_READ_TRANSFORM", cost_2))
        
        # 策略 3: Memory Copy 中变换
        cost_3 = self.estimate_memcopy_transform_cost(
            shape, producer_layout, consumer_layout)
        strategies.append(("FUSED_COPY_TRANSFORM", cost_3))
        
        # 选择代价最小的策略
        best_strategy = min(strategies, key=lambda x: x[1])
        
        return {
            "transform_needed": True,
            "best_strategy": best_strategy[0],
            "estimated_cost": best_strategy[1]
        }
\end{lstlisting}

\subsection{Elementwise 算子的特殊优势}

\textbf{关键观察}：Elementwise 算子（如 ReLU、Add）是布局变换融合的理想位置。

原因分析：
\begin{itemize}
  \item \textbf{布局不敏感}：Elementwise 算子对输入布局没有要求
  \item \textbf{可以透传布局}：输入什么布局，输出就什么布局
  \item \textbf{计算简单}：不会增加地址生成的复杂度
\end{itemize}

\begin{lstlisting}[caption={Elementwise 算子透传布局}]
class ReductionAnalyzer:
    """
    规约分析器
    
    分析每个算子是否包含规约操作，以此判断布局敏感性
    """
    
    REDUCTION_PATTERNS = {
        # 有规约的算子 -> 布局敏感
        'Conv': {'has_reduction': True, 'reduction_dims': ['C', 'R', 'S']},
        'MatMul': {'has_reduction': True, 'reduction_dims': ['K']},
        'Pool': {'has_reduction': True, 'reduction_dims': ['H', 'W']},
        
        # 无规约的算子 -> 布局不敏感，可以透传
        'ReLU': {'has_reduction': False, 'reduction_dims': []},
        'Add': {'has_reduction': False, 'reduction_dims': []},
        'Mul': {'has_reduction': False, 'reduction_dims': []},
    }
    
    @classmethod
    def is_layout_sensitive(cls, op_type):
        """判断算子是否对布局敏感"""
        pattern = cls.REDUCTION_PATTERNS.get(op_type, {})
        return pattern.get('has_reduction', True)
\end{lstlisting}

\textbf{最佳实践}：将布局变换插入到\textbf{布局敏感算子}之间的 Elementwise 算子链中，利用 Elementwise 的布局透传特性。

%======================================================================
\section{读取时变换 vs 写入时变换}
%======================================================================

布局变换可以在\textbf{读取阶段}或\textbf{写入阶段}完成。这两种方案在实现复杂度、性能和适用场景上有显著差异。

\subsection{写入时变换（Write-Time Transform）}

\subsubsection{原理}

Producer 在将计算结果写回内存时，直接按照下游期望的布局组织数据：

\begin{center}
\fbox{\parbox{0.9\textwidth}{
\textbf{写入时变换流程}：\\[0.5em]
Producer 计算单元 $\xrightarrow{\text{计算结果}}$ 
AGU (按目标布局计算地址) $\xrightarrow{\text{写入}}$ 
Memory (目标布局存储)
}}
\end{center}

\begin{verbatim}
Producer 计算循环:
  for n, c, h, w in compute_order:
      result = compute(n, c, h, w)
      
      # 写入时按 NHWC 布局计算地址
      addr = n * (H*W*C) + h * (W*C) + w * C + c
      memory[addr] = result
\end{verbatim}

\subsubsection{代码实现}

\begin{lstlisting}[caption={写入时变换的地址生成}]
class WriteTimeTransform:
    """
    写入时变换的实现
    
    核心思想：Producer 写回时，使用目标布局的步长计算写地址
    """
    
    def __init__(self, shape, target_layout):
        self.shape = shape
        # 计算目标布局的步长
        self.target_strides = self.compute_strides(shape, target_layout)
    
    def compute_strides(self, shape, layout_order):
        """根据 layout 顺序计算步长"""
        physical_shape = [shape[layout_order[i]] for i in range(len(shape))]
        
        physical_strides = [1] * len(shape)
        for i in range(len(shape) - 2, -1, -1):
            physical_strides[i] = physical_strides[i + 1] * physical_shape[i + 1]
        
        # 映射回逻辑步长
        logical_strides = [0] * len(shape)
        for physical_dim, logical_dim in enumerate(layout_order):
            logical_strides[logical_dim] = physical_strides[physical_dim]
        
        return tuple(logical_strides)
    
    def get_write_address(self, n, c, h, w, base_addr=0):
        """计算写入地址"""
        offset = (n * self.target_strides[0] + 
                  c * self.target_strides[1] +
                  h * self.target_strides[2] + 
                  w * self.target_strides[3])
        return base_addr + offset * 4  # 4 bytes per float32
\end{lstlisting}

\subsubsection{优缺点}

\textbf{优点}：
\begin{itemize}
  \item 数据一旦写入，后续所有 Consumer 都可以直接使用
  \item 适合一个 Producer 对应多个 Consumer 的情况
  \item 写入通常有更好的局部性（顺序写）
\end{itemize}

\textbf{缺点}：
\begin{itemize}
  \item Producer 需要知道 Consumer 的布局需求
  \item 如果不同 Consumer 需要不同布局，无法同时满足
  \item 写地址计算可能变复杂
\end{itemize}

\subsection{读取时变换（Read-Time Transform）}

\subsubsection{原理}

Consumer 在读取数据时，根据上游实际存储的布局计算读地址：

\begin{verbatim}
Consumer 计算循环 (期望 NHWC 顺序):
  for n, h, w, c in compute_order:  # NHWC 顺序
      # 读取时按源数据的 NCHW 布局计算地址
      addr = n * (C*H*W) + c * (H*W) + h * W + w
      data = memory[addr]
      
      result = compute(data)
\end{verbatim}

\subsubsection{代码实现}

\begin{lstlisting}[caption={读取时变换的地址生成}]
class ReadTimeTransform:
    """
    读取时变换的实现
    
    核心思想：Consumer 读取时，使用源布局的步长计算读地址
    """
    
    def __init__(self, shape, source_layout):
        self.shape = shape
        # 计算源布局的步长
        self.source_strides = self.compute_strides(shape, source_layout)
    
    def compute_strides(self, shape, layout_order):
        """根据 layout 顺序计算步长"""
        # 与 WriteTimeTransform 相同
        physical_shape = [shape[layout_order[i]] for i in range(len(shape))]
        
        physical_strides = [1] * len(shape)
        for i in range(len(shape) - 2, -1, -1):
            physical_strides[i] = physical_strides[i + 1] * physical_shape[i + 1]
        
        logical_strides = [0] * len(shape)
        for physical_dim, logical_dim in enumerate(layout_order):
            logical_strides[logical_dim] = physical_strides[physical_dim]
        
        return tuple(logical_strides)
    
    def get_read_address(self, n, c, h, w, base_addr=0):
        """计算读取地址"""
        offset = (n * self.source_strides[0] + 
                  c * self.source_strides[1] +
                  h * self.source_strides[2] + 
                  w * self.source_strides[3])
        return base_addr + offset * 4
\end{lstlisting}

\subsubsection{优缺点}

\textbf{优点}：
\begin{itemize}
  \item Consumer 独立决定如何读取，不影响 Producer
  \item 灵活性高，可以适配多种上游布局
  \item 适合数据来源不确定的场景（如多分支合并）
\end{itemize}

\textbf{缺点}：
\begin{itemize}
  \item 读取可能不连续，降低内存带宽利用率
  \item 每个 Consumer 都需要处理布局差异
  \item 读地址计算复杂度增加
\end{itemize}

\subsection{选择决策树}

\begin{lstlisting}[caption={读写时机选择的决策逻辑}]
def choose_transform_timing(producer, consumers, source_layout, target_layouts):
    """
    选择布局变换的时机：写入时 vs 读取时
    
    Args:
        producer: 生产者算子
        consumers: 消费者算子列表
        source_layout: 源布局
        target_layouts: 各消费者期望的布局
        
    Returns:
        "WRITE_TIME" 或 "READ_TIME"
    """
    
    # 规则 1: 如果所有 consumer 期望相同布局，写入时变换
    unique_layouts = set(target_layouts)
    if len(unique_layouts) == 1:
        return "WRITE_TIME"
    
    # 规则 2: 如果 consumer 数量少，读取时变换更灵活
    if len(consumers) <= 2:
        return "READ_TIME"
    
    # 规则 3: 分析写入连续性 vs 读取连续性
    write_continuity = analyze_continuity(
        producer.compute_order, list(unique_layouts)[0])
    
    avg_read_continuity = sum(
        analyze_continuity(c.compute_order, source_layout) 
        for c in consumers
    ) / len(consumers)
    
    if write_continuity > avg_read_continuity:
        return "WRITE_TIME"
    else:
        return "READ_TIME"


def analyze_continuity(compute_order, layout):
    """
    分析计算顺序与布局的匹配度
    
    返回 0-1 之间的分数，越高表示访问越连续
    """
    # 检查最内层循环是否对应最小步长的维度
    innermost_dim = compute_order[-1]
    layout_strides = compute_strides_for_layout(layout)
    
    min_stride_dim = min(range(len(layout_strides)), 
                         key=lambda d: layout_strides[d])
    
    if innermost_dim == min_stride_dim:
        return 1.0  # 完美连续
    else:
        return 0.5  # 部分连续
\end{lstlisting}

\subsection{决策总结}

\begin{center}
\begin{tabular}{lll}
\toprule
\textbf{场景} & \textbf{推荐方案} & \textbf{原因} \\
\midrule
单 Producer 多相同 Consumer & 写入时变换 & 一次变换多次使用 \\
多 Producer 单 Consumer & 读取时变换 & Consumer 统一处理 \\
计算顺序匹配目标布局 & 写入时变换 & 写入连续性好 \\
计算顺序匹配源布局 & 读取时变换 & 读取连续性好 \\
DRAM $\to$ SRAM 预取 & Memory Copy 融合 & 隐藏延迟 \\
\bottomrule
\end{tabular}
\end{center}

%======================================================================
\section{实现 Layout Transformation 的硬件单元}
%======================================================================

布局变换的高效实现需要专用硬件支持。本节介绍实现布局变换的核心硬件单元。

\subsection{地址生成单元（Address Generation Unit, AGU）}

AGU 是实现布局变换的核心硬件。它根据逻辑索引计算物理内存地址。

\subsubsection{基本架构}

\begin{lstlisting}[caption={AGU 硬件模型}]
class AddressGenerationUnit:
    """
    地址生成单元的硬件模型
    
    功能：根据多维索引和步长计算内存地址
    
    硬件实现：
      - 多个乘法器（index × stride）
      - 加法树（累加各维度贡献）
      - 基地址加法器
    """
    
    def __init__(self, num_dims=4):
        self.num_dims = num_dims
        # 配置寄存器
        self.base_addr = 0
        self.strides = [0] * num_dims
        self.bounds = [0] * num_dims  # 各维度的范围
    
    def configure(self, base_addr, strides, bounds):
        """
        配置 AGU 参数
        
        在算子执行前由控制器配置
        """
        self.base_addr = base_addr
        self.strides = strides
        self.bounds = bounds
    
    def compute_address(self, indices):
        """
        计算地址（硬件并行执行）
        
        addr = base + sum(index[d] * stride[d])
        
        硬件延迟：1-2 个时钟周期
        """
        offset = 0
        for d in range(self.num_dims):
            # 这里的乘法在硬件中并行执行
            offset += indices[d] * self.strides[d]
        
        return self.base_addr + offset
\end{lstlisting}

\subsubsection{支持布局变换的 AGU 设计}

标准 AGU 只需通过\textbf{配置不同的步长}即可支持任意布局：

\begin{lstlisting}[caption={AGU 配置示例}]
# 示例：(1, 64, 56, 56) 张量

# NCHW 布局配置
agu.configure(
    base_addr=0,
    strides=[64*56*56, 56*56, 56, 1],  # N, C, H, W
    bounds=[1, 64, 56, 56]
)

# NHWC 布局配置（相同硬件，不同参数）
agu.configure(
    base_addr=0,
    strides=[56*56*64, 1, 56*64, 64],  # N, C, H, W 的步长
    bounds=[1, 64, 56, 56]
)

# 关键：布局变换只是步长的重新配置，无需额外硬件
\end{lstlisting}

\subsection{DMA 控制器（Direct Memory Access Controller）}

DMA 控制器负责在内存层次之间搬移数据，是实现融合布局变换的理想位置。

\subsubsection{支持布局变换的 DMA 设计}

\begin{lstlisting}[caption={支持布局变换的 DMA 控制器}]
class LayoutAwareDMA:
    """
    支持布局变换的 DMA 控制器
    
    在数据搬移过程中完成布局变换，无需额外的 DRAM 访问
    """
    
    def __init__(self, read_agu, write_agu, buffer_size=256):
        self.read_agu = read_agu    # 读地址生成单元
        self.write_agu = write_agu  # 写地址生成单元
        self.buffer_size = buffer_size  # 内部缓冲区大小
    
    def configure_fused_copy(self, shape, src_layout, dst_layout,
                              src_base, dst_base):
        """
        配置融合布局变换的 DMA 传输
        """
        # 配置读 AGU（按源布局）
        src_strides = compute_strides(shape, src_layout)
        self.read_agu.configure(src_base, src_strides, shape)
        
        # 配置写 AGU（按目标布局）
        dst_strides = compute_strides(shape, dst_layout)
        self.write_agu.configure(dst_base, dst_strides, shape)
    
    def execute_transfer(self, total_elements):
        """
        执行数据传输
        
        硬件实现：
          1. 读 AGU 生成读地址，发起读请求
          2. 数据通过内部缓冲区
          3. 写 AGU 生成写地址，发起写请求
          
        读写可以流水线执行
        """
        for i in range(0, total_elements, self.buffer_size):
            batch_size = min(self.buffer_size, total_elements - i)
            
            # 并行生成读写地址
            read_addrs = [self.read_agu.compute_address(
                self.index_from_linear(i + j)) for j in range(batch_size)]
            write_addrs = [self.write_agu.compute_address(
                self.index_from_linear(i + j)) for j in range(batch_size)]
            
            # 执行读取
            data = [memory_read(addr) for addr in read_addrs]
            
            # 执行写入（数据被重新排列）
            for j, addr in enumerate(write_addrs):
                memory_write(addr, data[j])
\end{lstlisting}

\subsection{Scatter-Gather Engine}

对于复杂的非连续访问模式，Scatter-Gather 引擎提供更高效的实现：

\begin{lstlisting}[caption={Scatter-Gather 引擎}]
class ScatterGatherEngine:
    """
    Scatter-Gather 引擎
    
    支持复杂的非连续内存访问模式
    
    Gather: 从分散的源地址收集数据到连续缓冲区
    Scatter: 将连续缓冲区的数据分散写入到不同地址
    """
    
    def __init__(self, vector_width=16):
        self.vector_width = vector_width  # 并行处理的元素数
    
    def gather(self, addresses, dest_buffer):
        """
        Gather 操作：收集分散数据
        
        硬件实现：
          - 多个独立的读端口
          - 地址队列管理
          - 数据对齐单元
        """
        for i in range(0, len(addresses), self.vector_width):
            batch_addrs = addresses[i:i + self.vector_width]
            
            # 并行读取（硬件中同时发起多个读请求）
            for j, addr in enumerate(batch_addrs):
                dest_buffer[i + j] = memory_read(addr)
    
    def scatter(self, src_buffer, addresses):
        """
        Scatter 操作：分散写入数据
        
        硬件实现：
          - 多个独立的写端口
          - 写合并单元（Write Coalescing）
        """
        for i in range(0, len(addresses), self.vector_width):
            batch_addrs = addresses[i:i + self.vector_width]
            
            # 并行写入
            for j, addr in enumerate(batch_addrs):
                if i + j < len(src_buffer):
                    memory_write(addr, src_buffer[i + j])
    
    def fused_layout_transform(self, shape, src_layout, dst_layout,
                                src_base, dst_base):
        """
        使用 Gather-Process-Scatter 模式实现布局变换
        """
        src_strides = compute_strides(shape, src_layout)
        dst_strides = compute_strides(shape, dst_layout)
        
        total_elements = prod(shape)
        buffer = [0] * self.vector_width
        
        for batch_start in range(0, total_elements, self.vector_width):
            batch_size = min(self.vector_width, total_elements - batch_start)
            
            # 生成源地址（Gather）
            src_addrs = []
            for i in range(batch_size):
                idx = self.linear_to_multi_index(batch_start + i, shape)
                src_addrs.append(src_base + sum(
                    idx[d] * src_strides[d] for d in range(len(shape))))
            
            # Gather
            self.gather(src_addrs, buffer)
            
            # 生成目标地址（Scatter）
            dst_addrs = []
            for i in range(batch_size):
                idx = self.linear_to_multi_index(batch_start + i, shape)
                dst_addrs.append(dst_base + sum(
                    idx[d] * dst_strides[d] for d in range(len(shape))))
            
            # Scatter
            self.scatter(buffer, dst_addrs)
\end{lstlisting}

\subsection{片上网络（Network-on-Chip, NoC）支持}

在多核加速器中，NoC 也可以参与布局变换：

\begin{lstlisting}[caption={NoC 支持的布局变换}]
class NoCLayoutTransform:
    """
    利用片上网络实现分布式布局变换
    
    适用于数据分布在多个 PE 的场景
    """
    
    def __init__(self, num_pes, noc_topology):
        self.num_pes = num_pes
        self.noc_topology = noc_topology
    
    def distributed_transpose(self, local_data, src_partition, dst_partition):
        """
        分布式转置
        
        每个 PE 持有数据的一部分，通过 NoC 通信完成全局转置
        
        示例：将按行分区的矩阵转换为按列分区
        
        Args:
            local_data: 本地数据块
            src_partition: 源分区方式
            dst_partition: 目标分区方式
        """
        my_pe_id = get_current_pe_id()
        
        # 计算需要发送给其他 PE 的数据
        send_buffers = {}
        for target_pe in range(self.num_pes):
            if target_pe != my_pe_id:
                # 确定需要发送的数据子集
                data_to_send = self.compute_send_data(
                    local_data, my_pe_id, target_pe, 
                    src_partition, dst_partition)
                send_buffers[target_pe] = data_to_send
        
        # 全交换通信（All-to-All）
        recv_buffers = noc_all_to_all(send_buffers)
        
        # 组装本地结果
        result = self.assemble_local_result(
            local_data, recv_buffers, dst_partition)
        
        return result
\end{lstlisting}

\subsection{硬件设计总结}

\begin{center}
\begin{tabular}{llll}
\toprule
\textbf{硬件单元} & \textbf{功能} & \textbf{适用场景} & \textbf{设计复杂度} \\
\midrule
AGU & 地址计算 & 所有场景 & 低 \\
DMA + 双 AGU & 融合搬移 & DRAM $\leftrightarrow$ SRAM & 中 \\
Scatter-Gather & 非连续访问 & 复杂布局变换 & 中-高 \\
NoC & 分布式变换 & 多核加速器 & 高 \\
\bottomrule
\end{tabular}
\end{center}

\textbf{设计原则}：
\begin{enumerate}
  \item AGU 需要支持\textbf{可配置步长}，这是实现布局变换的基础
  \item DMA 控制器应配备\textbf{独立的读写 AGU}，支持融合布局变换
  \item 对于高性能需求，可以增加 Scatter-Gather 能力
  \item 大规模并行系统需要考虑 NoC 层面的数据重分布
\end{enumerate}

%======================================================================
\section{完整代码示例：端到端的布局变换}
%======================================================================

本节给出一个完整的代码示例，展示从分析到执行的完整流程。

\subsection{场景设定}

考虑以下神经网络片段：
\begin{verbatim}
Conv1 (NCHW output) -> ReLU -> Conv2 (expects NHWC input)
\end{verbatim}

需要在 Conv1 和 Conv2 之间完成 NCHW $\to$ NHWC 的布局变换。

\subsection{完整实现}

\begin{lstlisting}[caption={端到端布局变换示例}]
"""
完整的布局变换实现示例

演示从分析、决策到执行的完整流程
"""

from dataclasses import dataclass
from typing import Tuple, Dict
from enum import Enum
import math


# ============================================================
# 第一步：定义数据结构
# ============================================================

@dataclass
class TensorInfo:
    """张量信息"""
    name: str
    shape: Tuple[int, ...]
    layout: Tuple[int, ...]  # 维度存储顺序


@dataclass
class OperatorInfo:
    """算子信息"""
    name: str
    op_type: str
    input_layout_preference: Tuple[int, ...]
    output_layout: Tuple[int, ...]
    compute_order: Tuple[int, ...]


# ============================================================
# 第二步：布局分析
# ============================================================

def analyze_layout_mismatch(producer: OperatorInfo, 
                            consumer: OperatorInfo,
                            tensor_shape: Tuple[int, ...]):
    """
    分析两个算子之间的布局不匹配情况
    """
    src_layout = producer.output_layout
    dst_layout = consumer.input_layout_preference
    
    if src_layout == dst_layout:
        return {
            "mismatch": False,
            "message": "Layouts match, no transformation needed"
        }
    
    # 计算变换的数据量
    data_size = math.prod(tensor_shape) * 4  # float32
    
    return {
        "mismatch": True,
        "source_layout": src_layout,
        "target_layout": dst_layout,
        "tensor_shape": tensor_shape,
        "data_size_bytes": data_size,
        "transform_type": "TRANSPOSE" if len(src_layout) == len(dst_layout) else "RESHAPE"
    }


# ============================================================
# 第三步：选择变换策略
# ============================================================

class TransformStrategy(Enum):
    PRODUCER_WRITE = "producer_write"
    CONSUMER_READ = "consumer_read"
    MEMORY_COPY_FUSED = "memory_copy_fused"


def select_transform_strategy(analysis_result: Dict,
                               producer: OperatorInfo,
                               consumer: OperatorInfo) -> TransformStrategy:
    """
    选择最优的变换策略
    """
    if not analysis_result["mismatch"]:
        return None
    
    src_layout = analysis_result["source_layout"]
    dst_layout = analysis_result["target_layout"]
    
    # 计算各策略的代价
    
    # 策略 1: Producer 写入时变换
    # 检查 producer 的计算顺序是否与目标布局兼容
    producer_write_cost = compute_address_generation_cost(
        producer.compute_order, dst_layout)
    
    # 策略 2: Consumer 读取时变换
    consumer_read_cost = compute_address_generation_cost(
        consumer.compute_order, src_layout)
    
    # 策略 3: Memory Copy 融合
    # 假设总是可行，代价取决于数据搬移本身
    memcopy_cost = 1.0  # 归一化代价
    
    # 选择最小代价的策略
    costs = [
        (TransformStrategy.PRODUCER_WRITE, producer_write_cost),
        (TransformStrategy.CONSUMER_READ, consumer_read_cost),
        (TransformStrategy.MEMORY_COPY_FUSED, memcopy_cost),
    ]
    
    best = min(costs, key=lambda x: x[1])
    return best[0]


def compute_address_generation_cost(compute_order: Tuple[int, ...],
                                     layout: Tuple[int, ...]) -> float:
    """
    计算地址生成的代价
    
    如果计算顺序与布局匹配（最内层循环对应最小步长），
    则访问是连续的，代价低
    """
    # 检查最内层循环维度
    innermost_compute_dim = compute_order[-1]
    
    # 找到布局中最小步长的维度
    layout_list = list(layout)
    innermost_storage_dim = layout_list[-1]  # 最后一个是最内层存储
    
    if innermost_compute_dim == innermost_storage_dim:
        return 0.5  # 连续访问，代价低
    else:
        return 1.5  # 非连续访问，代价高


# ============================================================
# 第四步：生成地址配置
# ============================================================

def generate_address_config(strategy: TransformStrategy,
                            tensor_shape: Tuple[int, ...],
                            src_layout: Tuple[int, ...],
                            dst_layout: Tuple[int, ...],
                            producer: OperatorInfo,
                            consumer: OperatorInfo) -> Dict:
    """
    根据策略生成地址配置
    """
    
    def compute_strides(shape, layout_order):
        """计算指定布局的步长"""
        physical_shape = [shape[layout_order[i]] for i in range(len(shape))]
        physical_strides = [1] * len(shape)
        for i in range(len(shape) - 2, -1, -1):
            physical_strides[i] = physical_strides[i + 1] * physical_shape[i + 1]
        
        logical_strides = [0] * len(shape)
        for physical_dim, logical_dim in enumerate(layout_order):
            logical_strides[logical_dim] = physical_strides[physical_dim]
        
        return tuple(logical_strides)
    
    config = {"strategy": strategy.value}
    
    if strategy == TransformStrategy.PRODUCER_WRITE:
        # Producer 使用目标布局的步长写入
        config["producer_write_strides"] = compute_strides(tensor_shape, dst_layout)
        config["consumer_read_strides"] = compute_strides(tensor_shape, dst_layout)
        config["stored_layout"] = dst_layout
        
    elif strategy == TransformStrategy.CONSUMER_READ:
        # Consumer 使用源布局的步长读取
        config["producer_write_strides"] = compute_strides(tensor_shape, src_layout)
        config["consumer_read_strides"] = compute_strides(tensor_shape, src_layout)
        config["stored_layout"] = src_layout
        
    elif strategy == TransformStrategy.MEMORY_COPY_FUSED:
        # DMA 读写使用不同步长
        config["dma_read_strides"] = compute_strides(tensor_shape, src_layout)
        config["dma_write_strides"] = compute_strides(tensor_shape, dst_layout)
        config["producer_write_strides"] = compute_strides(tensor_shape, src_layout)
        config["consumer_read_strides"] = compute_strides(tensor_shape, dst_layout)
    
    return config


# ============================================================
# 第五步：执行演示
# ============================================================

def demo_layout_transform():
    """
    演示完整的布局变换流程
    """
    print("=" * 60)
    print("Layout Transformation 端到端演示")
    print("=" * 60)
    
    # 定义算子
    conv1 = OperatorInfo(
        name="conv1",
        op_type="Conv",
        input_layout_preference=(0, 1, 2, 3),  # NCHW
        output_layout=(0, 1, 2, 3),            # NCHW
        compute_order=(0, 1, 2, 3)             # 按 N, C, H, W 顺序计算
    )
    
    conv2 = OperatorInfo(
        name="conv2",
        op_type="Conv",
        input_layout_preference=(0, 2, 3, 1),  # NHWC
        output_layout=(0, 2, 3, 1),
        compute_order=(0, 2, 3, 1)             # 按 N, H, W, C 顺序计算
    )
    
    tensor_shape = (1, 64, 56, 56)  # 中间特征图
    
    print(f"\n场景: {conv1.name} -> {conv2.name}")
    print(f"张量形状: {tensor_shape}")
    print(f"数据大小: {math.prod(tensor_shape) * 4 / 1024:.1f} KB")
    
    # 步骤 1: 分析布局不匹配
    print("\n--- 步骤 1: 布局分析 ---")
    analysis = analyze_layout_mismatch(conv1, conv2, tensor_shape)
    print(f"布局不匹配: {analysis['mismatch']}")
    if analysis['mismatch']:
        print(f"  源布局 (NCHW): {analysis['source_layout']}")
        print(f"  目标布局 (NHWC): {analysis['target_layout']}")
    
    # 步骤 2: 选择变换策略
    print("\n--- 步骤 2: 策略选择 ---")
    strategy = select_transform_strategy(analysis, conv1, conv2)
    print(f"选择策略: {strategy.value}")
    
    # 步骤 3: 生成地址配置
    print("\n--- 步骤 3: 地址配置 ---")
    config = generate_address_config(
        strategy, tensor_shape,
        analysis['source_layout'], analysis['target_layout'],
        conv1, conv2
    )
    
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # 步骤 4: 显示具体的地址计算示例
    print("\n--- 步骤 4: 地址计算示例 ---")
    
    # 计算索引 (0, 32, 28, 28) 的地址
    test_index = (0, 32, 28, 28)
    
    nchw_strides = (64*56*56, 56*56, 56, 1)
    nhwc_strides = (56*56*64, 64, 56*64, 1)
    
    nchw_addr = sum(i * s for i, s in zip(test_index, nchw_strides))
    nhwc_addr = sum(i * s for i, s in zip(test_index, nhwc_strides))
    
    print(f"  测试索引 (n=0, c=32, h=28, w=28):")
    print(f"    NCHW 地址: {nchw_addr} (offset)")
    print(f"    NHWC 地址: {nhwc_addr} (offset)")
    print(f"    地址差异: {abs(nhwc_addr - nchw_addr)}")
    
    print("\n" + "=" * 60)
    print("演示完成")
    print("=" * 60)


if __name__ == "__main__":
    demo_layout_transform()
\end{lstlisting}

\subsection{运行结果}

\begin{verbatim}
============================================================
Layout Transformation 端到端演示
============================================================

场景: conv1 -> conv2
张量形状: (1, 64, 56, 56)
数据大小: 784.0 KB

--- 步骤 1: 布局分析 ---
布局不匹配: True
  源布局 (NCHW): (0, 1, 2, 3)
  目标布局 (NHWC): (0, 2, 3, 1)

--- 步骤 2: 策略选择 ---
选择策略: memory_copy_fused

--- 步骤 3: 地址配置 ---
  strategy: memory_copy_fused
  dma_read_strides: (200704, 3136, 56, 1)
  dma_write_strides: (200704, 1, 3584, 64)
  producer_write_strides: (200704, 3136, 56, 1)
  consumer_read_strides: (200704, 1, 3584, 64)

--- 步骤 4: 地址计算示例 ---
  测试索引 (n=0, c=32, h=28, w=28):
    NCHW 地址: 101948 (offset)
    NHWC 地址: 101920 (offset)
    地址差异: 28

============================================================
演示完成
============================================================
\end{verbatim}

%======================================================================
\section{总结}
%======================================================================

本文详细讨论了神经网络加速器中数据布局变换的四个核心问题：

\subsection{变换对象：权重 vs 激活值}

\begin{itemize}
  \item \textbf{权重}：静态数据，应在\textbf{离线阶段}完成布局变换，零运行时开销
  \item \textbf{激活值}：动态数据，需要在\textbf{运行时}处理，应通过融合优化来降低开销
\end{itemize}

\subsection{算子融合策略}

\begin{itemize}
  \item \textbf{与 Producer 融合}：写入时按目标布局组织，适合单 Producer 多 Consumer
  \item \textbf{与 Consumer 融合}：读取时适配源布局，适合多 Producer 单 Consumer
  \item \textbf{与 Memory Copy 融合}：利用必需的数据搬移，隐藏变换开销
  \item \textbf{Elementwise 算子}：布局不敏感，是插入变换的理想位置
\end{itemize}

\subsection{读取 vs 写入时机}

\begin{itemize}
  \item \textbf{写入时变换}：数据一次变换，多次使用；要求 Producer 知道下游需求
  \item \textbf{读取时变换}：灵活适配不同源布局；可能导致非连续读取
  \item 选择取决于\textbf{计算顺序与布局的匹配度}
\end{itemize}

\subsection{硬件实现}

\begin{itemize}
  \item \textbf{AGU（地址生成单元）}：核心组件，通过可配置步长支持任意布局
  \item \textbf{DMA 控制器}：配备独立读写 AGU，实现融合布局变换
  \item \textbf{Scatter-Gather 引擎}：处理复杂非连续访问模式
  \item \textbf{NoC}：大规模并行系统中的分布式数据重排
\end{itemize}

\vspace{1em}
\noindent\textbf{核心设计原则}：

\begin{enumerate}
  \item \textbf{避免单独的布局变换算子}（DRAM $\to$ DRAM），这会带来 2× 的额外内存访问
  \item \textbf{利用必需的数据搬移}来隐藏布局变换开销
  \item \textbf{AGU 的步长可配置性}是实现灵活布局支持的基础
  \item \textbf{编译期优化}可以消除大部分运行时布局变换需求
\end{enumerate}

\end{document}
