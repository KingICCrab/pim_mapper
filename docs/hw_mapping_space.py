#!/usr/bin/env python3
"""
PE Array H/W 维度映射空间 → Dataflow → 计算单元类型

这个表格回答：
- H方向映射什么维度？W方向映射什么维度？
- 这种组合是什么dataflow？
- 这种组合对应哪种计算单元？
"""

def print_table():
    print("""
╔══════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                        PE Array H/W 维度映射 → Dataflow → 计算单元类型                                    ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                          ║
║  卷积维度回顾:  Output[N,K,P,Q] = Σ_{r,s,c} Input[N,C,P+r,Q+s] × Weight[K,C,R,S]                          ║
║  • Output相关维度: K, P, Q, N  (并行时无需reduction)                                                      ║
║  • Reduction维度:  R, S, C     (并行时需要累加partial sum)                                                ║
║                                                                                                          ║
╠════════════╤════════════╤═══════════════╤═══════════════╤════════════════════════════════════════════════╣
║  H 方向     │  W 方向     │  Reduction    │  Dataflow     │  对应计算单元                                  ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  K         │  P×Q       │  None         │  Weight       │  ✓ TPU (Weight Stationary 视角)                ║
║            │  (或N)     │               │  Stationary   │  ✓ Scalar PE array                            ║
║            │            │               │               │  Weight沿K分布,同行PE共享同一Weight             ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  P×Q       │  K         │  None         │  Output       │  ✓ ShiDianNao                                 ║
║  (或N)     │            │               │  Stationary   │  ✓ Scalar PE array                            ║
║            │            │               │               │  Output tile固定,不同K用不同Weight             ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  K         │  C         │  W方向        │  ★ Tensor     │  ★ NVIDIA Tensor Core                         ║
║  (M)       │  (K_red)   │  (C累加)      │  Core 风格    │  ★ AMD Matrix Core                            ║
║            │            │               │               │  H=Output行, W=Reduction, 内部树累加           ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  C         │  K         │  H方向        │  Input        │  ✓ NVDLA (某些模式)                           ║
║  (K_red)   │  (N)       │  (C累加)      │  Stationary   │  ✓ 需要H方向reduction网络                     ║
║            │            │               │               │  Input沿C分布,需要累加partial sum              ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  K         │  K         │  None (但K    │  ★ TPU       │  ★ Google TPU Systolic Array                  ║
║  (systolic │  (systolic │  沿对角线     │  Systolic     │  Weight固定, Activation从左流入                 ║
║   row)     │   col)     │  流动)        │               │  Psum从上往下systolic传递                       ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  R×S       │  K         │  H方向        │  Row          │  ✓ Eyeriss                                    ║
║            │            │  (R×S累加)    │  Stationary   │  Filter行在H方向展开                           ║
║            │            │               │               │  需要累加R×S个partial sum                       ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  R×S       │  P×Q       │  H方向        │  Row          │  ✓ Eyeriss v2                                 ║
║            │            │  (R×S累加)    │  Stationary   │  Filter行×Output空间                           ║
║            │            │               │  (变体)       │                                                ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  K,C       │  P×Q       │  H方向        │  Mixed        │  ✓ 自定义加速器                               ║
║  (多维H)   │            │  (C累加)      │               │  K和C都在H方向展开                             ║
║            │            │               │               │  需要对C部分做reduction                        ║
╠════════════╪════════════╪═══════════════╪═══════════════╪════════════════════════════════════════════════╣
║            │            │               │               │                                                ║
║  C         │  C         │  H+W方向      │  ⚠️ 2D       │  ⚠️ 特殊硬件                                  ║
║  (split)   │  (split)   │  (2D累加)     │  Reduction    │  C维度拆分到两个方向                           ║
║            │            │               │               │  需要先行后列(或反过来)的2D reduction           ║
╠════════════╧════════════╧═══════════════╧═══════════════╧════════════════════════════════════════════════╣
║                                                                                                          ║
║  ★ 关键洞察:                                                                                             ║
║                                                                                                          ║
║  1. Tensor Core = H方向放Output维度(K), W方向放Reduction维度(C), 内部有硬件累加树                         ║
║     → 本质是 Output Stationary + 固定Reduction维度 + 硬件Reduction Tree                                  ║
║                                                                                                          ║
║  2. TPU Systolic = H和W都沿着同一个维度(K)的不同切片, 数据systolic流动                                    ║
║     → 本质是 Weight Stationary + Systolic数据流 + PE间传递Psum                                           ║
║                                                                                                          ║
║  3. Scalar PE Array = H和W可以任意映射, Reduction通过Buffer或PE网络完成                                   ║
║     → 最灵活, 但Reduction延迟最高                                                                        ║
║                                                                                                          ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════╝
""")

def print_tensor_core_detail():
    print("""
╔══════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                              Tensor Core 的精确 H/W 映射                                                  ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                          ║
║  矩阵乘法: C[M×N] = A[M×K] × B[K×N]                                                                       ║
║                                                                                                          ║
║  Tensor Core (16×16×16):                                                                                 ║
║  ┌────────────────────────────────────────────────────────────────┐                                      ║
║  │                         W 方向 (N=16)                          │                                      ║
║  │              ←────────────────────────────────→                │                                      ║
║  │         ┌────┬────┬────┬────┬────┬────┬────┬────┐             │                                      ║
║  │      ↑  │ C  │ C  │ C  │ C  │ C  │ C  │ C  │... │  ← 输出一行  │                                      ║
║  │      │  │0,0 │0,1 │0,2 │0,3 │0,4 │0,5 │0,6 │    │             │                                      ║
║  │      │  ├────┼────┼────┼────┼────┼────┼────┼────┤             │                                      ║
║  │   H  │  │ C  │ C  │ C  │ C  │ C  │ C  │ C  │... │             │                                      ║
║  │   方 M  │1,0 │1,1 │1,2 │1,3 │1,4 │1,5 │1,6 │    │             │                                      ║
║  │   向 =  ├────┼────┼────┼────┼────┼────┼────┼────┤             │                                      ║
║  │      16 │... │... │... │... │... │... │... │... │             │                                      ║
║  │      │  └────┴────┴────┴────┴────┴────┴────┴────┘             │                                      ║
║  │      ↓                                                        │                                      ║
║  └────────────────────────────────────────────────────────────────┘                                      ║
║                                                                                                          ║
║  每个 PE (如 C[i,j]) 的计算:                                                                              ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  C[i,j] = Σ_{k=0}^{15} A[i,k] × B[k,j]                          │                                     ║
║  │                                                                 │                                     ║
║  │  输入: A[i, 0:16] (一行, 16个元素) ─→ 从 H 方向广播到同一行      │                                     ║
║  │        B[0:16, j] (一列, 16个元素) ─→ 从 W 方向广播到同一列      │                                     ║
║  │                                                                 │                                     ║
║  │  内部: 16个乘法 + 16-way reduction tree ─→ 1个结果              │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
║  映射到卷积 (im2col后):                                                                                   ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  • M = K (output channels)           → H方向                    │                                     ║
║  │  • N = P×Q×N (output spatial×batch) → W方向                    │                                     ║
║  │  • K_reduction = C×R×S               → 内部reduction            │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════╝
""")

def print_tpu_systolic_detail():
    print("""
╔══════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                              TPU Systolic Array 的精确 H/W 映射                                           ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                          ║
║  TPU Systolic Array (128×128), Weight Stationary:                                                        ║
║                                                                                                          ║
║           Activation 从左边流入 (沿 W 方向)                                                               ║
║           ─────────────────────────────────→                                                             ║
║                                                                                                          ║
║      ┌────┬────┬────┬────┬────┐                                                                         ║
║   ↓  │W   │W   │W   │W   │... │  Weight[K=0, C=0:128] 预加载                                            ║
║   P  │0,0 │0,1 │0,2 │0,3 │    │                                                                         ║
║   s  ├────┼────┼────┼────┼────┤                                                                         ║
║   u  │W   │W   │W   │W   │... │  Weight[K=1, C=0:128] 预加载                                            ║
║   m  │1,0 │1,1 │1,2 │1,3 │    │                                                                         ║
║      ├────┼────┼────┼────┼────┤                                                                         ║
║   沿 │... │... │... │... │... │                                                                         ║
║   H  └────┴────┴────┴────┴────┘                                                                         ║
║   方      ↓    ↓    ↓    ↓                                                                              ║
║   向      Psum 向下 systolic 传递                                                                        ║
║   流                                                                                                     ║
║   出                                                                                                     ║
║                                                                                                          ║
║  数据流:                                                                                                  ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  Cycle 0: Act[0] 进入 PE[0,0], 计算 psum[0,0] = W[0,0]×Act[0]   │                                     ║
║  │  Cycle 1: Act[0] 移到 PE[0,1], Act[1] 进入 PE[0,0]              │                                     ║
║  │           psum[0,0] 传到 PE[1,0], 累加 W[1,0]×Act[0]            │                                     ║
║  │  ...                                                            │                                     ║
║  │  Cycle 127: 第一个完整的 Output 从底部流出                       │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
║  H/W 映射:                                                                                                ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  • H方向 = K (output channels, 128个)                           │                                     ║
║  │  • W方向 = C (input channels, 128个)  ← Reduction维度!          │                                     ║
║  │  • Reduction方式 = Systolic flow (psum沿H方向传递)              │                                     ║
║  │  • Activation 沿 W 方向流动, 每个PE看到所有C                     │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
║  ★ 关键区别 vs Tensor Core:                                                                              ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  Tensor Core: Reduction在PE内部完成 (硬件树, 1 cycle)           │                                     ║
║  │  TPU Systolic: Reduction通过PE间传递完成 (128 cycles pipeline)  │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════╝
""")

def print_mapping_space():
    print("""
╔══════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                              ILP 需要探索的 H/W 映射空间                                                   ║
╠══════════════════════════════════════════════════════════════════════════════════════════════════════════╣
║                                                                                                          ║
║  给定 PE Array: H_size × W_size (如 16×16)                                                               ║
║  给定 计算单元类型: scalar / systolic / tensor_core                                                       ║
║                                                                                                          ║
║  ILP 变量:                                                                                                ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  xb_h[j] ∈ divisors(dim_j)  : 维度j在H方向的并行因子            │                                     ║
║  │  xb_w[j] ∈ divisors(dim_j)  : 维度j在W方向的并行因子            │                                     ║
║  │                                                                 │                                     ║
║  │  约束:                                                          │                                     ║
║  │  ∏_j xb_h[j] ≤ H_size                                          │                                     ║
║  │  ∏_j xb_w[j] ≤ W_size                                          │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
║  不同计算单元的额外约束:                                                                                   ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │                                                                 │                                     ║
║  │  Scalar PE (最灵活):                                            │                                     ║
║  │    • 无额外约束                                                  │                                     ║
║  │    • Reduction通过buffer,代价加入目标函数                        │                                     ║
║  │                                                                 │                                     ║
║  │  Systolic Array:                                                │                                     ║
║  │    • 约束: xb_h[K] = H_size (K必须完全映射到H)                   │                                     ║
║  │    • 约束: xb_w[C] = W_size (C必须完全映射到W)                   │                                     ║
║  │    • Reduction: systolic延迟 = H_size cycles                    │                                     ║
║  │                                                                 │                                     ║
║  │  Tensor Core:                                                   │                                     ║
║  │    • 约束: xb_h只能用Output相关维度 (K,P,Q,N)                    │                                     ║
║  │    • 约束: xb_w只能用Output相关维度 (K,P,Q,N)                    │                                     ║
║  │    • 约束: Reduction维度(C)必须≤内部reduction_dim                │                                     ║
║  │    • Reduction: 内部完成,延迟=1 (pipelined)                     │                                     ║
║  │                                                                 │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
║  映射空间大小估算 (7维, 每维~10个因子):                                                                    ║
║  ┌─────────────────────────────────────────────────────────────────┐                                     ║
║  │  Scalar PE:    ~10^7 种组合 (需要ILP剪枝)                        │                                     ║
║  │  Systolic:     ~10^5 种组合 (K,C固定后剩余5维)                   │                                     ║
║  │  Tensor Core:  ~10^4 种组合 (只能用4个Output相关维度)            │                                     ║
║  └─────────────────────────────────────────────────────────────────┘                                     ║
║                                                                                                          ║
╚══════════════════════════════════════════════════════════════════════════════════════════════════════════╝
""")


if __name__ == "__main__":
    print_table()
    print("\n" + "="*100 + "\n")
    print_tensor_core_detail()
    print("\n" + "="*100 + "\n")
    print_tpu_systolic_detail()
    print("\n" + "="*100 + "\n")
    print_mapping_space()
